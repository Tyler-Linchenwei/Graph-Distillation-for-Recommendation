# Rankformer é¡¹ç›®è¿è¡Œæœºåˆ¶è¯¦è§£

## ğŸ“‹ ç›®å½•
1. [ç¨‹åºå¯åŠ¨æµç¨‹](#ç¨‹åºå¯åŠ¨æµç¨‹)
2. [æ•°æ®åŠ è½½æµç¨‹](#æ•°æ®åŠ è½½æµç¨‹)
3. [æ¨¡å‹åˆå§‹åŒ–æµç¨‹](#æ¨¡å‹åˆå§‹åŒ–æµç¨‹)
4. [è®­ç»ƒå¾ªç¯æµç¨‹](#è®­ç»ƒå¾ªç¯æµç¨‹)
5. [è¯„ä¼°æµç¨‹](#è¯„ä¼°æµç¨‹)
6. [å…³é”®å‡½æ•°è°ƒç”¨é“¾](#å…³é”®å‡½æ•°è°ƒç”¨é“¾)

---

## ğŸš€ ç¨‹åºå¯åŠ¨æµç¨‹

### 1. å…¥å£ç‚¹ï¼š`code/main.py`

å½“ä½ è¿è¡Œ `python code/main.py --data=Ali-Display --use_gcn --use_rankformer ...` æ—¶ï¼Œç¨‹åºæŒ‰ä»¥ä¸‹é¡ºåºæ‰§è¡Œï¼š

```
main.py (ç¬¬24-28è¡Œ)
  â†“
parse.py (ç¬¬84è¡Œ) - è§£æå‘½ä»¤è¡Œå‚æ•°
  â†“
dataloader.py (ç¬¬90è¡Œ) - åˆ›å»ºå…¨å±€datasetå¯¹è±¡
  â†“
main.py (ç¬¬144è¡Œ) - åˆ›å»ºModelå¯¹è±¡
  â†“
main.py (ç¬¬164è¡Œ) - åˆå§‹éªŒè¯
  â†“
main.py (ç¬¬172è¡Œ) - è®­ç»ƒå¾ªç¯
```

### 2. åˆå§‹åŒ–é˜¶æ®µï¼ˆmain.py ç¬¬137-164è¡Œï¼‰

```python
# æ­¥éª¤1: è§£æå‚æ•°ï¼ˆparse.pyè‡ªåŠ¨æ‰§è¡Œï¼‰
args = parse_args()  # è§£ææ‰€æœ‰å‘½ä»¤è¡Œå‚æ•°

# æ­¥éª¤2: åŠ è½½æ•°æ®ï¼ˆdataloader.pyè‡ªåŠ¨æ‰§è¡Œï¼‰
dataset = MyDataset(...)  # è¯»å–train/valid/testæ–‡ä»¶

# æ­¥éª¤3: åˆ›å»ºæ¨¡å‹
model = Model(dataset).to(args.device)  # åˆå§‹åŒ–åµŒå…¥å±‚ã€GCNã€Rankformer

# æ­¥éª¤4: åˆå§‹éªŒè¯ï¼ˆepoch=0ï¼‰
valid(epoch=0)  # è¯„ä¼°æœªè®­ç»ƒçš„æ¨¡å‹æ€§èƒ½
```

---

## ğŸ“Š æ•°æ®åŠ è½½æµç¨‹

### `dataloader.py` çš„æ‰§è¡Œè¿‡ç¨‹

```python
# 1. è¯»å–ä¸‰ä¸ªæ–‡ä»¶
train_data = pd.read_table('data/Ali-Display/train.txt')  # æ ¼å¼: user_id item_id
valid_data = pd.read_table('data/Ali-Display/valid.txt')
test_data = pd.read_table('data/Ali-Display/test.txt')

# 2. è½¬æ¢ä¸ºTensorå¹¶æ’åº
self.train_user, self.train_item = train_data[:, 0], train_data[:, 1]
# æŒ‰ç”¨æˆ·IDæ’åºï¼Œæ–¹ä¾¿åç»­æ‰¹æ¬¡å¤„ç†

# 3. ç»Ÿè®¡åŸºæœ¬ä¿¡æ¯
self.num_users = max(æ‰€æœ‰ç”¨æˆ·ID) + 1
self.num_items = max(æ‰€æœ‰ç‰©å“ID) + 1

# 4. æ„å»ºè¯„ä¼°æ‰¹æ¬¡ï¼ˆbuild_batchå‡½æ•°ï¼‰
# å°†ç”¨æˆ·åˆ†æˆå¤šä¸ªæ‰¹æ¬¡ï¼Œæ¯ä¸ªæ‰¹æ¬¡åŒ…å«test_batch_sizeä¸ªç”¨æˆ·
self.batch_users = [ç”¨æˆ·æ‰¹æ¬¡1, ç”¨æˆ·æ‰¹æ¬¡2, ...]
self.train_batch = [æ¯ä¸ªæ‰¹æ¬¡å¯¹åº”çš„è®­ç»ƒäº¤äº’]
self.test_batch = [æ¯ä¸ªæ‰¹æ¬¡å¯¹åº”çš„æµ‹è¯•äº¤äº’]
self.valid_batch = [æ¯ä¸ªæ‰¹æ¬¡å¯¹åº”çš„éªŒè¯äº¤äº’]
```

**å…³é”®æ•°æ®ç»“æ„ï¼š**
- `train_user`: `[num_interactions]` - æ‰€æœ‰è®­ç»ƒäº¤äº’çš„ç”¨æˆ·ID
- `train_item`: `[num_interactions]` - æ‰€æœ‰è®­ç»ƒäº¤äº’çš„ç‰©å“ID
- `batch_users`: `List[Tensor]` - æ¯ä¸ªè¯„ä¼°æ‰¹æ¬¡çš„ç”¨æˆ·IDåˆ—è¡¨

---

## ğŸ—ï¸ æ¨¡å‹åˆå§‹åŒ–æµç¨‹

### `Model.__init__()` (model.py ç¬¬128-164è¡Œ)

```python
# 1. åˆ›å»ºå¯å­¦ä¹ çš„åµŒå…¥å±‚
self.embedding_user = nn.Embedding(num_users, hidden_dim)  # [num_users, 64]
self.embedding_item = nn.Embedding(num_items, hidden_dim)  # [num_items, 64]
# éšæœºåˆå§‹åŒ–ï¼Œstd=0.1

# 2. åˆ›å»ºGCNå’ŒRankformerç»„ä»¶ï¼ˆä¸åŒ…å«å¯å­¦ä¹ å‚æ•°ï¼‰
self.GCN = GCN(dataset, gcn_left, gcn_right)
self.Rankformer = Rankformer(dataset, rankformer_alpha)

# 3. åˆ›å»ºä¼˜åŒ–å™¨
self.optimizer = torch.optim.Adam([embedding_user, embedding_item], lr=learning_rate)

# 4. åˆå§‹åŒ–ç¼“å­˜å˜é‡ï¼ˆç”¨äºå­˜å‚¨è®¡ç®—å¥½çš„åµŒå…¥ï¼‰
self._users = None      # æœ€ç»ˆç”¨æˆ·åµŒå…¥
self._items = None      # æœ€ç»ˆç‰©å“åµŒå…¥
self._users_cl = None   # å¯¹æ¯”å­¦ä¹ ç”¨çš„ç”¨æˆ·åµŒå…¥
self._items_cl = None   # å¯¹æ¯”å­¦ä¹ ç”¨çš„ç‰©å“åµŒå…¥
```

**æ³¨æ„ï¼š** GCNå’ŒRankformeræœ¬èº«æ²¡æœ‰å¯å­¦ä¹ å‚æ•°ï¼Œå®ƒä»¬åªæ˜¯å¯¹åµŒå…¥è¿›è¡Œå˜æ¢ã€‚åªæœ‰`embedding_user`å’Œ`embedding_item`ä¼šè¢«ä¼˜åŒ–å™¨æ›´æ–°ã€‚

---

## ğŸ”„ è®­ç»ƒå¾ªç¯æµç¨‹

### ä¸»å¾ªç¯ï¼ˆmain.py ç¬¬172-190è¡Œï¼‰

```python
epoch = 1
while epoch <= max_epochs:
    # 1. æ‰§è¡Œä¸€ä¸ªepochçš„è®­ç»ƒ
    train()  # â†’ model.train_func()
    
    # 2. å®šæœŸéªŒè¯ï¼ˆæ¯valid_intervalä¸ªepochï¼‰
    if epoch % valid_interval == 0:
        found_best = valid(epoch)  # â†’ model.valid_func()
        
        # 3. æ—©åœæ£€æŸ¥
        if not found_best and (epoch - best_epoch) >= stopping_step * valid_interval:
            break  # åœæ­¢è®­ç»ƒ
    
    epoch += 1
```

### è®­ç»ƒä¸€ä¸ªepochï¼š`train_func()` (model.py ç¬¬361-381è¡Œ)

```python
def train_func(self):
    self.train()  # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
    
    if loss_batch_size == 0:
        # å…¨é‡è®­ç»ƒï¼šä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰è®­ç»ƒæ•°æ®
        return train_func_one_batch(train_user, train_item)
    else:
        # æ‰¹é‡è®­ç»ƒï¼šå°†è®­ç»ƒæ•°æ®åˆ†æˆå¤šä¸ªbatch
        shuffled_indices = torch.randperm(train_user.shape[0])
        train_user_shuffled = train_user[shuffled_indices]
        train_item_shuffled = train_item[shuffled_indices]
        
        # å¯¹æ¯ä¸ªbatchæ‰§è¡Œè®­ç»ƒ
        for i in range(0, len(train_user), loss_batch_size):
            batch_u = train_user_shuffled[i:i+loss_batch_size]
            batch_i = train_item_shuffled[i:i+loss_batch_size]
            loss = train_func_one_batch(batch_u, batch_i)
        
        return å¹³å‡æŸå¤±
```

### å•æ‰¹æ¬¡è®­ç»ƒï¼š`train_func_one_batch()` (model.py ç¬¬383-400è¡Œ)

```python
def train_func_one_batch(self, u, i):
    # u: [batch_size] - ç”¨æˆ·ID
    # i: [batch_size] - æ­£æ ·æœ¬ç‰©å“ID
    
    # 1. è®¡ç®—åµŒå…¥ï¼ˆæ ¸å¿ƒï¼ï¼‰
    self.computer()  # â†’ æ‰§è¡ŒGCNå’ŒRankformerä¼ æ’­ï¼Œæ›´æ–°self._userså’Œself._items
    
    # 2. è®¡ç®—æŸå¤±
    train_loss = self.loss_func(u, i)  # â†’ loss_bpr(u, i)
    
    # 3. åå‘ä¼ æ’­å’Œå‚æ•°æ›´æ–°
    self.optimizer.zero_grad()  # æ¸…é›¶æ¢¯åº¦
    train_loss.backward()        # è®¡ç®—æ¢¯åº¦
    self.optimizer.step()        # æ›´æ–°embedding_userå’Œembedding_item
    
    return train_loss
```

### è®¡ç®—åµŒå…¥ï¼š`computer()` (model.py ç¬¬166-250è¡Œ)

è¿™æ˜¯**æ•´ä¸ªæ¨¡å‹çš„æ ¸å¿ƒ**ï¼Œæ¯æ¬¡è®­ç»ƒå’Œè¯„ä¼°éƒ½ä¼šè°ƒç”¨ï¼š

```python
def computer(self):
    # 1. è·å–åŸå§‹åµŒå…¥
    users_emb = self.embedding_user.weight  # [num_users, hidden_dim]
    items_emb = self.embedding_item.weight  # [num_items, hidden_dim]
    all_emb = torch.cat([users_emb, items_emb], dim=0)  # [num_users+num_items, hidden_dim]
    
    # 2. GCNä¼ æ’­ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if args.use_gcn:
        for layer in range(gcn_layers):
            all_emb = self.GCN(all_emb, u_train, i_train)  # å›¾å·ç§¯ä¼ æ’­
            # å¯é€‰ï¼šæ·»åŠ å¯¹æ¯”å­¦ä¹ å™ªå£°
            if args.use_cl and layer == cl_layer - 1:
                emb_cl = all_emb  # ä¿å­˜ç”¨äºå¯¹æ¯”å­¦ä¹ 
    
    # 3. Rankformerä¼ æ’­ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if args.use_rankformer:
        for layer in range(rankformer_layers):
            rec_emb = self.Rankformer(all_emb, u_train, i_train)
            # æ®‹å·®è¿æ¥
            all_emb = (1 - tau) * all_emb + tau * rec_emb
    
    # 4. åˆ†å‰²å¹¶ä¿å­˜
    self._users, self._items = torch.split(all_emb, [num_users, num_items])
    self._users_cl, self._items_cl = torch.split(emb_cl, [num_users, num_items])
```

**å…³é”®ç‚¹ï¼š**
- `computer()`æ¯æ¬¡éƒ½ä¼šé‡æ–°è®¡ç®—åµŒå…¥ï¼Œå› ä¸º`embedding_user`å’Œ`embedding_item`åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šæ›´æ–°
- GCNå’ŒRankformeræ˜¯**æ— çŠ¶æ€çš„**ï¼Œå®ƒä»¬åªæ ¹æ®å½“å‰çš„åµŒå…¥å’Œäº¤äº’å›¾è¿›è¡Œè®¡ç®—

### è®¡ç®—æŸå¤±ï¼š`loss_bpr()` (model.py ç¬¬402-468è¡Œ)

```python
def loss_bpr(self, u, i):
    # u: [batch_size] - ç”¨æˆ·ID
    # i: [batch_size] - æ­£æ ·æœ¬ç‰©å“ID
    
    # 1. è´Ÿé‡‡æ ·ï¼šä¸ºæ¯ä¸ª(u,i)ç”Ÿæˆä¸€ä¸ªè´Ÿæ ·æœ¬j
    j = negative_sampling(u, i, num_items)  # jä¸åœ¨ç”¨æˆ·uçš„äº¤äº’å†å²ä¸­
    
    # 2. è·å–åµŒå…¥
    u_emb = self._users[u]      # [batch_size, hidden_dim] - æœ€ç»ˆç”¨æˆ·åµŒå…¥
    i_emb = self._items[i]      # [batch_size, hidden_dim] - æ­£æ ·æœ¬åµŒå…¥
    j_emb = self._items[j]      # [batch_size, hidden_dim] - è´Ÿæ ·æœ¬åµŒå…¥
    
    # 3. è®¡ç®—åˆ†æ•°
    scores_ui = (u_emb * i_emb).sum(dim=-1)  # [batch_size] - æ­£æ ·æœ¬åˆ†æ•°
    scores_uj = (u_emb * j_emb).sum(dim=-1)  # [batch_size] - è´Ÿæ ·æœ¬åˆ†æ•°
    
    # 4. BPRæŸå¤±ï¼šå¸Œæœ›scores_ui > scores_uj
    loss_bpr = F.softplus(scores_uj - scores_ui).mean()
    
    # 5. L2æ­£åˆ™åŒ–
    u_emb0 = self.embedding_user(u)  # åŸå§‹åµŒå…¥
    i_emb0 = self.embedding_item(i)
    j_emb0 = self.embedding_item(j)
    reg_loss = (u_emb0.norm(2)**2 + i_emb0.norm(2)**2 + j_emb0.norm(2)**2) / batch_size
    
    # 6. å¯¹æ¯”å­¦ä¹ æŸå¤±ï¼ˆå¯é€‰ï¼‰
    if args.use_cl:
        cl_loss = InfoNCE(self._users[u_unique], self._users_cl[u_unique], tau)
        loss_total = loss_bpr + reg_lambda * reg_loss + cl_lambda * cl_loss
    else:
        loss_total = loss_bpr + reg_lambda * reg_loss
    
    return loss_total
```

---

## ğŸ“ˆ è¯„ä¼°æµç¨‹

### éªŒè¯/æµ‹è¯•ï¼š`valid()` (main.py ç¬¬73-134è¡Œ)

```python
def valid(epoch):
    # 1. åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
    valid_pre, valid_recall, valid_ndcg = model.valid_func()
    
    # 2. æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ä½³æ¨¡å‹
    if valid_ndcg[-1] > best_valid_ndcg:
        best_valid_ndcg = valid_ndcg[-1]
        best_epoch = epoch
        
        # 3. åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°ï¼ˆä»…å½“æ‰¾åˆ°æœ€ä½³æ¨¡å‹æ—¶ï¼‰
        test_pre, test_recall, test_ndcg = model.test_func()
        
        # 4. å¯é€‰ï¼šä¿å­˜åµŒå…¥
        if args.save_emb:
            model.save_emb()
    
    return found_best
```

### è¯„ä¼°å‡½æ•°ï¼š`evaluate()` (model.py ç¬¬252-343è¡Œ)

```python
def evaluate(self, test_batch, test_degree):
    self.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    
    # 1. è®¡ç®—åµŒå…¥ï¼ˆå¦‚æœè¿˜æ²¡è®¡ç®—ï¼‰
    if self._users is None:
        self.computer()
    
    user_emb = self._users  # [num_users, hidden_dim]
    item_emb = self._items  # [num_items, hidden_dim]
    
    # 2. æ‰¹æ¬¡å¤„ç†ç”¨æˆ·
    with torch.no_grad():  # ä¸è®¡ç®—æ¢¯åº¦ï¼ŒèŠ‚çœå†…å­˜
        for batch_users, batch_train, ground_true in zip(...):
            # 3. è®¡ç®—ç”¨æˆ·å¯¹æ‰€æœ‰ç‰©å“çš„è¯„åˆ†
            user_e = user_emb[batch_users]  # [batch_size, hidden_dim]
            rating = user_e @ item_emb.T    # [batch_size, num_items]
            
            # 4. æ’é™¤è®­ç»ƒé›†äº¤äº’ï¼ˆè®¾ä¸ºè´Ÿæ— ç©·ï¼‰
            rating[batch_train[:, 0] - batch_users[0], batch_train[:, 1]] = -inf
            
            # 5. è·å–Top-Kæ¨è
            _, pred_items = torch.topk(rating, k=max_K, dim=1)  # [batch_size, max_K]
            
            # 6. è®¡ç®—æŒ‡æ ‡ï¼ˆPrecision@K, Recall@K, NDCG@Kï¼‰
            pre, recall, ndcg = test(pred_items, ground_true, test_degree)
            
            # 7. ç´¯åŠ æŒ‡æ ‡
            all_pre += pre
            all_recall += recall
            all_ndcg += ndcg
    
    # 8. è¿”å›å¹³å‡æŒ‡æ ‡
    return all_pre / all_cnt, all_recall / all_cnt, all_ndcg / all_cnt
```

**è¯„ä¼°çš„å…³é”®ç‚¹ï¼š**
- ä½¿ç”¨`torch.no_grad()`ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ŒèŠ‚çœå†…å­˜å’Œè®¡ç®—
- å¿…é¡»æ’é™¤è®­ç»ƒé›†äº¤äº’ï¼Œç¡®ä¿æ¨èçš„æ˜¯"æœªè§è¿‡"çš„ç‰©å“
- æŒ‰ç”¨æˆ·æ‰¹æ¬¡å¤„ç†ï¼Œé¿å…ä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰ç”¨æˆ·çš„è¯„åˆ†çŸ©é˜µï¼ˆå†…å­˜çˆ†ç‚¸ï¼‰

---

## ğŸ”— å…³é”®å‡½æ•°è°ƒç”¨é“¾

### è®­ç»ƒæ—¶çš„è°ƒç”¨é“¾

```
main.py: train()
  â†“
model.py: train_func()
  â†“
model.py: train_func_one_batch(u, i)
  â”œâ”€â†’ computer()  # è®¡ç®—åµŒå…¥
  â”‚   â”œâ”€â†’ GCN.forward()  # å›¾å·ç§¯
  â”‚   â””â”€â†’ Rankformer.forward()  # Rankformerä¼ æ’­
  â”œâ”€â†’ loss_bpr(u, i)  # è®¡ç®—æŸå¤±
  â”‚   â”œâ”€â†’ negative_sampling()  # è´Ÿé‡‡æ ·
  â”‚   â””â”€â†’ InfoNCE()  # å¯¹æ¯”å­¦ä¹ æŸå¤±ï¼ˆå¯é€‰ï¼‰
  â”œâ”€â†’ loss.backward()  # åå‘ä¼ æ’­
  â””â”€â†’ optimizer.step()  # æ›´æ–°å‚æ•°
```

### è¯„ä¼°æ—¶çš„è°ƒç”¨é“¾

```
main.py: valid(epoch)
  â†“
model.py: valid_func()
  â†“
model.py: evaluate(test_batch, test_degree)
  â”œâ”€â†’ computer()  # è®¡ç®—åµŒå…¥ï¼ˆå¦‚æœè¿˜æ²¡è®¡ç®—ï¼‰
  â”œâ”€â†’ è®¡ç®—è¯„åˆ†çŸ©é˜µ
  â”œâ”€â†’ torch.topk()  # è·å–Top-Kæ¨è
  â””â”€â†’ test()  # è®¡ç®—Precision/Recall/NDCG
```

---

## ğŸ’¡ å…³é”®ç†è§£ç‚¹

### 1. **ä¸ºä»€ä¹ˆæ¯æ¬¡è®­ç»ƒéƒ½è¦è°ƒç”¨`computer()`ï¼Ÿ**

å› ä¸º`embedding_user`å’Œ`embedding_item`åœ¨æ¯æ¬¡`optimizer.step()`åéƒ½ä¼šæ›´æ–°ï¼Œæ‰€ä»¥éœ€è¦é‡æ–°è®¡ç®—GCNå’ŒRankformerçš„è¾“å‡ºã€‚

### 2. **GCNå’ŒRankformerçš„åŒºåˆ«ï¼Ÿ**

- **GCN**: åŸºäºå›¾ç»“æ„çš„ç®€å•èšåˆï¼Œé€šè¿‡é‚»å±…èŠ‚ç‚¹çš„åŠ æƒå¹³å‡æ¥æ›´æ–°åµŒå…¥
- **Rankformer**: åŸºäºæ’åºç›®æ ‡çš„å¤æ‚èšåˆï¼ŒåŒæ—¶è€ƒè™‘æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬ï¼Œä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶

### 3. **ä¸ºä»€ä¹ˆè¯„ä¼°æ—¶è¦æ’é™¤è®­ç»ƒé›†äº¤äº’ï¼Ÿ**

è¿™æ˜¯æ¨èç³»ç»Ÿçš„æ ‡å‡†åšæ³•ï¼šæˆ‘ä»¬æƒ³çŸ¥é“æ¨¡å‹èƒ½å¦æ¨èç”¨æˆ·**æœªè§è¿‡**çš„ç‰©å“ï¼Œè€Œä¸æ˜¯ç®€å•åœ°è®°ä½è®­ç»ƒæ•°æ®ã€‚

### 4. **æ‰¹é‡è®­ç»ƒ vs å…¨é‡è®­ç»ƒ**

- `loss_batch_size=0`: å…¨é‡è®­ç»ƒï¼Œä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰è®­ç»ƒæ•°æ®ï¼ˆå†…å­˜å ç”¨å¤§ï¼‰
- `loss_batch_size>0`: æ‰¹é‡è®­ç»ƒï¼Œåˆ†æ‰¹å¤„ç†ï¼ˆå†…å­˜å‹å¥½ï¼Œä½†éœ€è¦æ‰“ä¹±æ•°æ®ï¼‰

### 5. **æ—©åœæœºåˆ¶**

å¦‚æœè¿ç»­`stopping_step`æ¬¡éªŒè¯éƒ½æ²¡æœ‰æå‡ï¼Œå°±åœæ­¢è®­ç»ƒï¼Œé¿å…è¿‡æ‹Ÿåˆã€‚

---

## ğŸ“ æ€»ç»“

æ•´ä¸ªé¡¹ç›®çš„è¿è¡Œæœºåˆ¶å¯ä»¥æ¦‚æ‹¬ä¸ºï¼š

1. **åˆå§‹åŒ–**ï¼šåŠ è½½æ•°æ® â†’ åˆ›å»ºæ¨¡å‹ â†’ åˆå§‹éªŒè¯
2. **è®­ç»ƒå¾ªç¯**ï¼šè®¡ç®—åµŒå…¥ â†’ è®¡ç®—æŸå¤± â†’ åå‘ä¼ æ’­ â†’ æ›´æ–°å‚æ•° â†’ å®šæœŸéªŒè¯
3. **è¯„ä¼°**ï¼šè®¡ç®—åµŒå…¥ â†’ è®¡ç®—è¯„åˆ† â†’ Top-Kæ¨è â†’ è®¡ç®—æŒ‡æ ‡
4. **æ—©åœ**ï¼šéªŒè¯æŒ‡æ ‡ä¸å†æå‡æ—¶åœæ­¢è®­ç»ƒ

æ ¸å¿ƒæ˜¯`computer()`å‡½æ•°ï¼Œå®ƒå°†åŸå§‹åµŒå…¥é€šè¿‡GCNå’ŒRankformerè½¬æ¢ä¸ºæœ€ç»ˆçš„ç”¨æˆ·/ç‰©å“è¡¨ç¤ºï¼Œç„¶åç”¨äºè®¡ç®—æŸå¤±ï¼ˆè®­ç»ƒï¼‰æˆ–è¯„åˆ†ï¼ˆè¯„ä¼°ï¼‰ã€‚
